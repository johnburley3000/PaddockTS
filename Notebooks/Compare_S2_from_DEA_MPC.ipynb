{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01fd8372-d897-435a-b99e-ad8d0b051000",
   "metadata": {},
   "source": [
    "### Purpose:\n",
    "\n",
    "In order to get PaddockTS running without dependency on DEA, we need to find a new way to download analaysis-ready Sentinel data (or raw Sentinel and then pre-process)\n",
    "\n",
    "A prime candidate is from microft planetary computer (MPC), becuase anyone can get an accound and access Sentinel1 and 2 data. \n",
    "https://planetarycomputer.microsoft.com/docs/quickstarts/reading-stac/\n",
    "\n",
    "But it seems that the S2 data from MCP might have slightly different pre-processing to DEA. It mentioned a Bottom of Atmosphere correction. And the cloud mask is not automatically applied. \n",
    "\n",
    "This notebook will evaluate S2 time series downloaded using the MPC and DEA for the same time and place of interest. \n",
    "\n",
    "### Tests:\n",
    "1. Are the same captures included using both methods?\n",
    "2. Are the band values correlated? Visalise side-by-side and check biplots.\n",
    "3. Can the s2cloudless mask be applied to the data downloaded from MPC to make it compatible?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d33107-5995-4968-92cc-09c0c0275e68",
   "metadata": {},
   "source": [
    "### Step 1: prep and download some sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479247c7-7fa1-476f-a6f2-98fdd2d3c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xarray as xr\n",
    "import rioxarray  # activate the rio accessor\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import rasterio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a14d46f-77aa-49ea-8045-301311bdd5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stub = 'TEST4'\n",
    "out_dir = '/g/data/xe2/John/Data/PadSeg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53308e6f-4bf9-4a2c-97e1-b58ba418f0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:                     (time: 10, y: 205, x: 194)\n",
      "Coordinates:\n",
      "  * time                        (time) datetime64[ns] 2019-06-25T00:27:29.882...\n",
      "  * y                           (y) float64 -4.424e+06 -4.424e+06 ... -4.426e+06\n",
      "  * x                           (x) float64 1.388e+07 1.388e+07 ... 1.388e+07\n",
      "    spatial_ref                 int32 6933\n",
      "Data variables: (12/31)\n",
      "    nbart_coastal_aerosol       (time, y, x) float32 57.0 57.0 ... 263.0 263.0\n",
      "    nbart_blue                  (time, y, x) float32 221.0 219.0 ... 584.0 332.0\n",
      "    nbart_green                 (time, y, x) float32 413.0 441.0 ... 916.0 560.0\n",
      "    nbart_red                   (time, y, x) float32 579.0 558.0 ... 614.0\n",
      "    nbart_red_edge_1            (time, y, x) float32 861.0 861.0 ... 1.267e+03\n",
      "    nbart_red_edge_2            (time, y, x) float32 1.298e+03 ... 2.395e+03\n",
      "    ...                          ...\n",
      "    oa_nbart_contiguity         (time, y, x) uint8 1 1 1 1 1 1 1 ... 1 1 1 1 1 1\n",
      "    oa_s2cloudless_mask         (time, y, x) uint8 1 1 1 1 1 1 1 ... 1 1 1 1 1 1\n",
      "    NDVI                        (time, y, x) float32 0.4222 0.4361 ... 0.689\n",
      "    kNDVI                       (time, y, x) float32 0.1764 0.1879 ... 0.442\n",
      "    LAI                         (time, y, x) float32 0.4599 0.4767 ... 1.575\n",
      "    SAVI                        (time, y, x) float32 0.1812 0.1855 ... 0.456\n",
      "Attributes:\n",
      "    crs:           epsg:6933\n",
      "    grid_mapping:  spatial_ref\n"
     ]
    }
   ],
   "source": [
    "## DEA Sentinel 2 data\n",
    "with open(out_dir+stub+'_ds2.pkl', 'rb') as handle:\n",
    "    ds2_DEA = pickle.load(handle)\n",
    "\n",
    "print(ds2_DEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ee44ad-b4bb-46dd-8d43-509012cf08fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:      (y: 205, x: 194, time: 30)\n",
      "Coordinates:\n",
      "  * y            (y) float64 -4.424e+06 -4.424e+06 ... -4.426e+06 -4.426e+06\n",
      "  * x            (x) float64 1.388e+07 1.388e+07 ... 1.388e+07 1.388e+07\n",
      "    spatial_ref  int32 6933\n",
      "  * time         (time) datetime64[ns] 2019-06-05T00:20:59.024000 ... 2019-10...\n",
      "Data variables:\n",
      "    B01          (time, y, x) float32 5.115e+03 5.115e+03 ... 459.0 225.0\n",
      "    B02          (time, y, x) float32 5.036e+03 5.176e+03 ... 691.0 449.0\n",
      "    B03          (time, y, x) float32 4.676e+03 4.688e+03 ... 1.13e+03 690.0\n",
      "    B04          (time, y, x) float32 4.32e+03 4.284e+03 ... 1.36e+03 830.0\n",
      "    B05          (time, y, x) float32 4.467e+03 4.38e+03 ... 1.94e+03 1.121e+03\n",
      "    B06          (time, y, x) float32 4.424e+03 4.33e+03 ... 2.671e+03 2.652e+03\n",
      "    B07          (time, y, x) float32 4.315e+03 4.181e+03 ... 3.121e+03 3.32e+03\n",
      "    B08          (time, y, x) float32 4.744e+03 4.828e+03 ... 3.692e+03\n",
      "    B8A          (time, y, x) float32 4.188e+03 4.109e+03 ... 3.695e+03\n",
      "    B11          (time, y, x) float32 2.981e+03 2.924e+03 ... 1.857e+03\n",
      "    B12          (time, y, x) float32 1.902e+03 1.869e+03 ... 1.056e+03\n"
     ]
    }
   ],
   "source": [
    "## MPC Sentinel 2 data\n",
    "with open(out_dir+stub+'_ds2-L2A.pkl', 'rb') as handle:\n",
    "    ds2_L2A = pickle.load(handle)\n",
    "\n",
    "print(ds2_L2A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a54eb47-7c57-4534-8849-9405a90c6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MPC Sentinel 1 data\n",
    "with open(out_dir+stub+'_ds1.pkl', 'rb') as handle:\n",
    "    ds1 = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adec35f6-4bea-4da7-948f-e9b80a5d0dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. images\n",
      "Sentinel 2 DEA: 10\n",
      "Sentinel 2 MPC: 30\n",
      "Sentinel 1 MPC: 30\n"
     ]
    }
   ],
   "source": [
    "print(\"N. images\")\n",
    "print('Sentinel 2 DEA:', len(ds2_DEA.time))\n",
    "print('Sentinel 2 MPC:',len(ds2_L2A.time))\n",
    "print('Sentinel 1 MPC:',len(ds1.time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea69636-a352-4e73-8ffa-93259ce27839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds2_DEA.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a85f97d-1354-41c7-b5a1-5e25d677b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds2_L2A.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06b02de7-b193-4c81-90e3-ccb25a2937ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds1.time.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c01b1-1fd9-410e-ba32-1dea5bcaa319",
   "metadata": {},
   "source": [
    "### Normalise data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690d3f3-9b11-40f4-911f-819be07bd414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754ad4a-5afb-4f3a-93ae-576b36bd6a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc18ca5-fe73-4e54-9a36-0c15a2a4944b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ac19a5f-0b7d-49fe-bf98-45085088fdd9",
   "metadata": {},
   "source": [
    "### Step 2 - Compare the S2 data from both sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e6da68-a534-402a-be9f-91b8aaa9c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from s2cloudless import S2PixelCloudDetector\n",
    "\n",
    "def add_cloud_probability_and_mask(ds, \n",
    "                                   bands=['B02', 'B03', 'B04', 'B05', 'B06', \n",
    "                                          'B07', 'B08', 'B8A', 'B11', 'B12'],\n",
    "                                   scale_factor=10000,\n",
    "                                  threshold = 0.3):\n",
    "    \"\"\"\n",
    "    Adds cloud probability and binary cloud mask variables to a Sentinel-2 time series dataset.\n",
    "    \n",
    "    Parameters:\n",
    "      ds (xarray.Dataset): Input dataset with Sentinel-2 time series data.\n",
    "                           It must have dimensions 'time', 'y', and 'x' and contain\n",
    "                           the specified bands.\n",
    "      bands (list of str): List of band names to use.\n",
    "                           For 10-band mode, use:\n",
    "                           ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12'].\n",
    "      scale_factor (float): Factor to convert digital numbers to reflectance.\n",
    "                            Default is 10000.\n",
    "      threshold (float): Cloud probability threshold (passed to the cloud detector).\n",
    "    \n",
    "    Returns:\n",
    "      xarray.Dataset: A new dataset with two additional variables:\n",
    "                      - 'cloud_probability' (float32, range [0,1])\n",
    "                      - 'cloud_mask' (int, 0=clear, 1=cloud)\n",
    "                      Both with shape (time, y, x).\n",
    "    \"\"\"\n",
    "    # Initialize the cloud detector in 10-band mode (all_bands=False is default)\n",
    "    cloud_detector = S2PixelCloudDetector(threshold=threshold, average_over=4, dilation_size=2, all_bands=False)\n",
    "\n",
    "    # Lists to hold cloud probability maps and cloud masks for each time step\n",
    "    cloud_prob_list = []\n",
    "    cloud_mask_list = []\n",
    "    \n",
    "    # Loop over each time step\n",
    "    for t in ds.time:\n",
    "        band_arrays = []\n",
    "        for band in bands:\n",
    "            # Select the data for the current time, convert to float32, and scale to reflectance.\n",
    "            arr = ds[band].sel(time=t).values.astype(np.float32) / scale_factor\n",
    "            band_arrays.append(arr)\n",
    "        # Stack the bands along the last axis; resulting shape: (y, x, len(bands))\n",
    "        img = np.stack(band_arrays, axis=-1)\n",
    "        \n",
    "        # The detector expects an input with a leading dimension for the number of images,\n",
    "        # so add an extra axis: shape becomes (1, y, x, len(bands))\n",
    "        img_expanded = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # Compute the cloud probability map.\n",
    "        # This returns an array of shape (N, y, x). Since N=1, take the first element.\n",
    "        cp = cloud_detector.get_cloud_probability_maps(img_expanded)[0]\n",
    "        cloud_prob_list.append(cp)\n",
    "        \n",
    "        # Compute the binary cloud mask using the probability map.\n",
    "        # The method expects an array of shape (N, y, x), so add a leading axis to cp.\n",
    "        mask = cloud_detector.get_mask_from_prob(np.expand_dims(cp, axis=0), threshold=threshold)[0]\n",
    "        cloud_mask_list.append(mask)\n",
    "    \n",
    "    # Stack the lists along the time axis; resulting shape: (time, y, x)\n",
    "    cloud_prob_array = np.stack(cloud_prob_list, axis=0)\n",
    "    cloud_mask_array = np.stack(cloud_mask_list, axis=0)\n",
    "    \n",
    "    # Create a new dataset (or copy the original) and add the new variables\n",
    "    ds_out = ds.copy()\n",
    "    ds_out['cloud_probability'] = (('time', 'y', 'x'), cloud_prob_array.astype(np.float32))\n",
    "    ds_out['cloud_mask'] = (('time', 'y', 'x'), cloud_mask_array.astype(np.int8))\n",
    "    \n",
    "    return ds_out\n",
    "\n",
    "# Example usage:\n",
    "# ds_with_clouds = add_cloud_probability_and_mask(your_xarray_dataset)\n",
    "# print(ds_with_clouds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0002e4-f899-4111-9577-246b362e37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2_L2A_cm = add_cloud_probability_and_mask(ds2_L2A)\n",
    "print(ds2_L2A_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795404cb-1e41-4d82-a703-a25a622f7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_l2a_clouds(ds2_L2A_cm):\n",
    "    \"\"\"\n",
    "    Create a subplot for each time step in ds2_L2A_cm showing:\n",
    "      - Left: RGB composite using bands B04 (red), B03 (green), B02 (blue)\n",
    "      - Middle: Cloud Probability (with a colorbar)\n",
    "      - Right: Cloud Mask (binary image)\n",
    "      \n",
    "    Parameters:\n",
    "        ds2_L2A_cm (xarray.Dataset): Dataset with Sentinel-2 L2A data including \n",
    "                                     B02, B03, B04, cloud_probability, and cloud_mask.\n",
    "    \"\"\"\n",
    "    # Determine the number of time steps\n",
    "    n_time = ds2_L2A_cm.dims['time']\n",
    "\n",
    "    # Create subplots: one row per time step, three columns (RGB, Cloud Probability, Cloud Mask)\n",
    "    fig, axes = plt.subplots(n_time, 3, figsize=(15, 2.5 * n_time))\n",
    "\n",
    "    # Ensure axes is 2D even if there's only one time step\n",
    "    if n_time == 1:\n",
    "        axes = np.array([axes])\n",
    "    \n",
    "    # Loop over each time step\n",
    "    for i, t in enumerate(ds2_L2A_cm.time.values):\n",
    "        # --- Construct RGB image ---\n",
    "        red = ds2_L2A_cm['B04'].sel(time=t).values\n",
    "        green = ds2_L2A_cm['B03'].sel(time=t).values\n",
    "        blue = ds2_L2A_cm['B02'].sel(time=t).values\n",
    "        rgb = np.stack([red, green, blue], axis=-1)\n",
    "        # Normalize the RGB image; adjust the divisor as needed (e.g., 3000 here)\n",
    "        rgb_norm = np.clip(rgb / 3000.0, 0, 1)\n",
    "        \n",
    "        # --- Plot RGB (Left Column) ---\n",
    "        ax_rgb = axes[i, 0]\n",
    "        ax_rgb.imshow(rgb_norm)\n",
    "        ax_rgb.set_title(f\"RGB {np.datetime_as_string(t, unit='D')}\")\n",
    "        ax_rgb.axis('off')\n",
    "        \n",
    "        # --- Extract and Plot Cloud Probability (Middle Column) ---\n",
    "        cp = ds2_L2A_cm['cloud_probability'].sel(time=t).values\n",
    "        ax_cp = axes[i, 1]\n",
    "        im_cp = ax_cp.imshow(cp, cmap='viridis')\n",
    "        ax_cp.set_title(\"Cloud Probability\")\n",
    "        ax_cp.axis('off')\n",
    "        fig.colorbar(im_cp, ax=ax_cp, fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # --- Extract and Plot Cloud Mask (Right Column) ---\n",
    "        cm = ds2_L2A_cm['cloud_mask'].sel(time=t).values\n",
    "        ax_cm = axes[i, 2]\n",
    "        ax_cm.imshow(cm, cmap='gray')\n",
    "        ax_cm.set_title(\"Cloud Mask\")\n",
    "        ax_cm.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83fca5-b668-44dc-be9e-1a76e5f856b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_l2a_clouds(ds2_L2A_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4deaac-7e32-4fbe-ab73-b332341d4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def compare_sentinel_data(ds2_DEA, ds2_L2A_cm):\n",
    "    \"\"\"\n",
    "    Compare Sentinel-2 data from two processing chains by plotting four panels for each time step,\n",
    "    matching on the date (ignoring time-of-day).\n",
    "    \n",
    "    The four panels (columns) are:\n",
    "      1. L2A RGB composite (using B04, B03, B02) from ds2_L2A_cm.\n",
    "      2. DEA (NBART) RGB composite (using nbart_red, nbart_green, nbart_blue) from ds2_DEA (if available for that date).\n",
    "      3. Cloud Mask from ds2_L2A_cm.\n",
    "      4. Scatter plot comparing the red band values (L2A vs. DEA) if DEA data is available.\n",
    "      \n",
    "    Parameters:\n",
    "      ds2_DEA (xarray.Dataset): DEA-processed dataset with bands nbart_red, nbart_green, nbart_blue.\n",
    "      ds2_L2A_cm (xarray.Dataset): L2A dataset with bands B04, B03, B02 and cloud_mask.\n",
    "    \"\"\"\n",
    "    # Build a dictionary mapping dates (YYYY-MM-DD) to the corresponding time value in ds2_DEA.\n",
    "    dea_date_dict = {}\n",
    "    for t in ds2_DEA.time.values:\n",
    "        date_str = np.datetime_as_string(t, unit='D')\n",
    "        # If multiple DEA observations exist for the same date, we keep the first occurrence.\n",
    "        if date_str not in dea_date_dict:\n",
    "            dea_date_dict[date_str] = t\n",
    "    \n",
    "    # Use the time values from ds2_L2A_cm as the reference timeline.\n",
    "    l2a_times = ds2_L2A_cm.time.values\n",
    "    num_times = len(l2a_times)\n",
    "    \n",
    "    # Create a figure with one row per time step and 4 columns.\n",
    "    fig, axes = plt.subplots(num_times, 4, figsize=(16, 4 * num_times))\n",
    "    \n",
    "    # Ensure axes is 2D even if there's only one time step.\n",
    "    if num_times == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "    \n",
    "    # Simple normalization function: scales image using the 2nd and 98th percentiles.\n",
    "    def normalize(img):\n",
    "        img_min, img_max = np.percentile(img, [2, 98])\n",
    "        return np.clip((img - img_min) / (img_max - img_min), 0, 1)\n",
    "    \n",
    "    # Loop over each time step from ds2_L2A_cm.\n",
    "    for i, t in enumerate(l2a_times):\n",
    "        # Use the full timestamp for display and the date-only string for matching.\n",
    "        time_str = np.datetime_as_string(t, unit='s')\n",
    "        date_str = np.datetime_as_string(t, unit='D')\n",
    "        \n",
    "        # --- Column 1: L2A RGB Composite ---\n",
    "        ds2_L2A_time = ds2_L2A_cm.sel(time=t)\n",
    "        l2a_red = ds2_L2A_time['B04'].values\n",
    "        l2a_green = ds2_L2A_time['B03'].values\n",
    "        l2a_blue = ds2_L2A_time['B02'].values\n",
    "        l2a_rgb = np.stack((l2a_red, l2a_green, l2a_blue), axis=-1)\n",
    "        \n",
    "        # Normalize each channel for display.\n",
    "        l2a_rgb_norm = np.zeros_like(l2a_rgb, dtype=float)\n",
    "        for band in range(3):\n",
    "            l2a_rgb_norm[..., band] = normalize(l2a_rgb[..., band])\n",
    "        \n",
    "        ax0 = axes[i, 0]\n",
    "        ax0.imshow(l2a_rgb_norm)\n",
    "        ax0.set_title(f\"L2A RGB\\n{time_str}\")\n",
    "        ax0.axis('off')\n",
    "        \n",
    "        # --- Column 2: DEA RGB Composite (if available for the matching date) ---\n",
    "        if date_str in dea_date_dict:\n",
    "            ds2_DEA_time = ds2_DEA.sel(time=dea_date_dict[date_str])\n",
    "            dea_red = ds2_DEA_time['nbart_red'].values\n",
    "            dea_green = ds2_DEA_time['nbart_green'].values\n",
    "            dea_blue = ds2_DEA_time['nbart_blue'].values\n",
    "            dea_rgb = np.stack((dea_red, dea_green, dea_blue), axis=-1)\n",
    "            \n",
    "            dea_rgb_norm = np.zeros_like(dea_rgb, dtype=float)\n",
    "            for band in range(3):\n",
    "                dea_rgb_norm[..., band] = normalize(dea_rgb[..., band])\n",
    "            \n",
    "            ax1 = axes[i, 1]\n",
    "            ax1.imshow(dea_rgb_norm)\n",
    "            ax1.set_title(f\"DEA RGB\\n{date_str}\")\n",
    "            ax1.axis('off')\n",
    "        else:\n",
    "            ax1 = axes[i, 1]\n",
    "            ax1.text(0.5, 0.5, 'Missing Data', ha='center', va='center', fontsize=12)\n",
    "            ax1.axis('off')\n",
    "        \n",
    "        # --- Column 3: Cloud Mask from L2A ---\n",
    "        ax2 = axes[i, 2]\n",
    "        cloud_mask = ds2_L2A_time['cloud_mask'].values\n",
    "        ax2.imshow(cloud_mask, cmap='gray')\n",
    "        ax2.set_title(\"Cloud Mask\")\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # --- Column 4: Scatter Plot (Red band: L2A vs. DEA) ---\n",
    "        ax3 = axes[i, 3]\n",
    "        if date_str in dea_date_dict:\n",
    "            # Flatten arrays so each point represents a pixel.\n",
    "            dea_red_flat = dea_red.flatten()\n",
    "            l2a_red_flat = l2a_red.flatten()\n",
    "            ax3.scatter(l2a_red_flat, dea_red_flat, s=1, alpha=0.5)\n",
    "            ax3.set_xlabel(\"L2A Red\")\n",
    "            ax3.set_ylabel(\"DEA Red\")\n",
    "            ax3.set_title(\"Red Band Scatter\")\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'Missing Data', ha='center', va='center', fontsize=12)\n",
    "            ax3.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ec6a1-6ba7-4a2b-be8b-0d3cc3eef48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_sentinel_data(ds2_DEA, ds2_L2A_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8e0f7-49b3-4a55-92ac-f5f8ebb76dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b9e96-06ae-4090-8dab-53e4b70f4b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b6ccc37-1400-45a4-8d99-861f20e3b502",
   "metadata": {},
   "source": [
    "# Trying Copermicus download method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2163b3dd-4066-42d3-a343-0991a2e7fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, geojson_to_wkt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1731e2a-9f70-40c5-9c78-472bc8d2ef1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='apihub.copernicus.eu', port=443): Max retries exceeded with url: /apihub/search?format=json&rows=100&start=0&q=beginPosition%3A%5B%222015-12-19T00%3A00%3A00Z%22+TO+%222015-12-29T00%3A00%3A00Z%22%5D+platformname%3A%22Sentinel-2%22+footprint%3A%22Intersects%28GEOMETRYCOLLECTION%28POLYGON%28%28149.0413+-35.2574%2C149.0413+-35.3157%2C149.1131+-35.3157%2C149.1131+-35.2574%2C149.0413+-35.2574%29%29%29%29%22 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x14ec08de3c50>, 'Connection to apihub.copernicus.eu timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/connectionpool.py:492\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    491\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 492\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/connectionpool.py:1097\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1097\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/connection.py:212\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x14ec08de3c50>, 'Connection to apihub.copernicus.eu timed out. (connect timeout=None)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    843\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 845\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='apihub.copernicus.eu', port=443): Max retries exceeded with url: /apihub/search?format=json&rows=100&start=0&q=beginPosition%3A%5B%222015-12-19T00%3A00%3A00Z%22+TO+%222015-12-29T00%3A00%3A00Z%22%5D+platformname%3A%22Sentinel-2%22+footprint%3A%22Intersects%28GEOMETRYCOLLECTION%28POLYGON%28%28149.0413+-35.2574%2C149.0413+-35.3157%2C149.1131+-35.3157%2C149.1131+-35.2574%2C149.0413+-35.2574%29%29%29%29%22 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x14ec08de3c50>, 'Connection to apihub.copernicus.eu timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# search by polygon, time, and SciHub query keywords\u001b[39;00m\n\u001b[1;32m      9\u001b[0m footprint \u001b[38;5;241m=\u001b[39m geojson_to_wkt(read_geojson(ROI))\n\u001b[0;32m---> 11\u001b[0m products \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m20151219\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2015\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m29\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mplatformname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSentinel-2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# convert to Pandas DataFrame\u001b[39;00m\n\u001b[1;32m     16\u001b[0m products_df \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mto_dataframe(products)\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/sentinelsat/sentinel.py:282\u001b[0m, in \u001b[0;36mSentinelAPI.query\u001b[0;34m(self, area, date, raw, area_relation, order_by, limit, offset, **keywords)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning query: order_by=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, limit=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, offset=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, query=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m     order_by,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     query,\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    281\u001b[0m formatted_order_by \u001b[38;5;241m=\u001b[39m _format_order_by(order_by)\n\u001b[0;32m--> 282\u001b[0m response, count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatted_order_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m products\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse_opensearch_response(response)\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/sentinelsat/sentinel.py:355\u001b[0m, in \u001b[0;36mSentinelAPI._load_query\u001b[0;34m(self, query, order_by, limit, offset)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, order_by\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     products, count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_subquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# repeat query until all results have been loaded\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     max_offset \u001b[38;5;241m=\u001b[39m count\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/sentinelsat/sentinel.py:388\u001b[0m, in \u001b[0;36mSentinelAPI._load_subquery\u001b[0;34m(self, query, order_by, limit, offset)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Unlike POST, DHuS only accepts latin1 charset in the GET params\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl_limit_semaphore:\n\u001b[0;32m--> 388\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_scihub_response(response, query_string\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# store last status code (for testing)\u001b[39;00m\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/g/data/xe2/John/geospatenv/lib/python3.11/site-packages/requests/adapters.py:507\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[0;32m--> 507\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='apihub.copernicus.eu', port=443): Max retries exceeded with url: /apihub/search?format=json&rows=100&start=0&q=beginPosition%3A%5B%222015-12-19T00%3A00%3A00Z%22+TO+%222015-12-29T00%3A00%3A00Z%22%5D+platformname%3A%22Sentinel-2%22+footprint%3A%22Intersects%28GEOMETRYCOLLECTION%28POLYGON%28%28149.0413+-35.2574%2C149.0413+-35.3157%2C149.1131+-35.3157%2C149.1131+-35.2574%2C149.0413+-35.2574%29%29%29%29%22 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x14ec08de3c50>, 'Connection to apihub.copernicus.eu timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "# connect to the API\n",
    "# NOT PROPERLY SET UP\n",
    "\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "\n",
    "api = SentinelAPI('john.burley@anu.edu.au', 'CANola$$$2024', 'https://apihub.copernicus.eu/apihub')\n",
    "\n",
    "ROI = '/home/106/jb5097/Projects/PaddockTS/Planet_dl/ARBO.geojson'\n",
    "# search by polygon, time, and SciHub query keywords\n",
    "footprint = geojson_to_wkt(read_geojson(ROI))\n",
    "\n",
    "products = api.query(footprint,\n",
    "                     date=('20151219', date(2015, 12, 29)),\n",
    "                     platformname='Sentinel-2')\n",
    "\n",
    "# convert to Pandas DataFrame\n",
    "products_df = api.to_dataframe(products)\n",
    "\n",
    "# sort and limit to first 5 sorted products\n",
    "products_df_sorted = products_df.sort_values(['cloudcoverpercentage', 'ingestiondate'], ascending=[True, True])\n",
    "products_df_sorted = products_df_sorted.head(5)\n",
    "\n",
    "# download sorted and reduced products\n",
    "api.download_all(products_df_sorted.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807e5a4-9ad5-4007-baa7-cb6d8538dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import zipfile\n",
    "import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from sentinelsat import SentinelAPI, geojson_to_wkt\n",
    "from s2cloudless import S2PixelCloudDetector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f12a80-0dcb-4028-a81a-7ade16ca599d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api = SentinelAPI('john.burley@anu.edu.au', 'CANola$$$2024', 'https://apihub.copernicus.eu/apihub')\n",
    "\n",
    "ROI = '/home/106/jb5097/Projects/PaddockTS/Planet_dl/ARBO.geojson'\n",
    "\n",
    "# Load area of interest from a GeoJSON file\n",
    "with open(ROI) as f:\n",
    "    roi_geojson = json.load(f)\n",
    "# Convert the first feature to a WKT string\n",
    "footprint = geojson_to_wkt(roi_geojson['features'][0])\n",
    "\n",
    "# Define date range (YYYYMMDD format)\n",
    "start_date = '20220101'\n",
    "end_date   = '20220131'\n",
    "date_range = (start_date, end_date)\n",
    "\n",
    "# Query for Sentinel-2 Level-2A products with moderate cloud cover\n",
    "products = api.query(footprint,\n",
    "                     date=date_range,\n",
    "                     platformname='Sentinel-2',\n",
    "                     processinglevel='Level-2A',\n",
    "                     cloudcoverpercentage=(0, 30))\n",
    "\n",
    "# Optionally inspect results\n",
    "products_df = api.to_dataframe(products)\n",
    "print(products_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9145936-b878-482d-948c-2c256724f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For this example, pick the first product from the query\n",
    "product_id = list(products.keys())[0]\n",
    "\n",
    "# Download the product into a directory called 'downloads'\n",
    "download_dir = 'downloads'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "api.download(product_id, directory_path=download_dir)\n",
    "\n",
    "# --- Step 2: Extract & Load Selected Bands ---\n",
    "\n",
    "# The product is downloaded as a zip file.\n",
    "# Its name is typically the product title with a .zip extension.\n",
    "product_title = products_df.loc[product_id]['title']\n",
    "zip_path = os.path.join(download_dir, product_title + '.zip')\n",
    "\n",
    "# Extract the SAFE archive\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(download_dir)\n",
    "\n",
    "# Locate the SAFE directory (ends with .SAFE)\n",
    "safe_dir = os.path.join(download_dir, product_title + '.SAFE')\n",
    "\n",
    "# Sentinel-2 L2A stores data in the GRANULE directory.\n",
    "# For 10m resolution bands (B02, B03, B04, B08) the files are in the R10m folder.\n",
    "granule_dir = glob.glob(os.path.join(safe_dir, 'GRANULE', '*'))[0]\n",
    "img_data_dir = os.path.join(granule_dir, 'IMG_DATA', 'R10m')\n",
    "\n",
    "# Build a dictionary mapping band names to file paths.\n",
    "# (Adjust the glob pattern if needed.)\n",
    "band_files = {\n",
    "    'B02': glob.glob(os.path.join(img_data_dir, '*_B02_10m.jp2'))[0],\n",
    "    'B03': glob.glob(os.path.join(img_data_dir, '*_B03_10m.jp2'))[0],\n",
    "    'B04': glob.glob(os.path.join(img_data_dir, '*_B04_10m.jp2'))[0],\n",
    "    'B08': glob.glob(os.path.join(img_data_dir, '*_B08_10m.jp2'))[0],\n",
    "}\n",
    "\n",
    "# Open each band as a DataArray with rioxarray and merge into one Dataset.\n",
    "da_list = []\n",
    "for band, path in band_files.items():\n",
    "    da = rioxarray.open_rasterio(path)\n",
    "    # Remove the band dimension if it exists and rename the DataArray\n",
    "    da = da.squeeze('band').rename(band)\n",
    "    da_list.append(da)\n",
    "\n",
    "# Merge into an xarray Dataset\n",
    "ds = xr.merge(da_list)\n",
    "\n",
    "# Convert digital numbers to reflectance.\n",
    "# Sentinel-2 L2A products are typically scaled by 10000.\n",
    "ds = ds / 10000.0\n",
    "\n",
    "# --- Step 3: Compute and Apply the s2cloudless Mask ---\n",
    "\n",
    "# Prepare the image for s2cloudless:\n",
    "# s2cloudless expects an array of shape (height, width, channels)\n",
    "# Ensure the bands are in the order: B02, B03, B04, B08\n",
    "img_array = np.stack([ds[band].values for band in ['B02', 'B03', 'B04', 'B08']], axis=-1)\n",
    "\n",
    "# Initialize the s2cloudless cloud detector (tweak threshold as needed)\n",
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)\n",
    "\n",
    "# Generate the binary cloud mask (shape: height x width, dtype=bool)\n",
    "cloud_mask = cloud_detector.get_cloud_mask(img_array)\n",
    "\n",
    "# Add the cloud mask as a new variable in the dataset.\n",
    "# Here we assume the spatial dimensions are named 'y' and 'x' (as set by rioxarray).\n",
    "ds['cloud_mask'] = (('y', 'x'), cloud_mask)\n",
    "\n",
    "# Now, ds is an xarray Dataset containing your selected Sentinel-2 bands and a cloud mask.\n",
    "print(ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
